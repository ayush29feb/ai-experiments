{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN MNIST.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayush29feb/nn-experiments/blob/master/gan/GAN_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "jnC_3AJQMkII",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Generative Adversarial Networks: MNIST\n",
        "\n",
        "A simple GAN for generating handwritten digits drawings similar to MNIST Dataset"
      ]
    },
    {
      "metadata": {
        "id": "g0JtIWeRH3hz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7SqXbsEFLnUW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d3d6b6b-6805-437d-8e48-cc11306324be"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.mlab as mlab\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torch.autograd import Variable\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "if use_cuda:\n",
        "  print('Using GPU: %s'% torch.cuda.get_device_name(0))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using GPU: Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ynaf-cO9QbPm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Parameters"
      ]
    },
    {
      "metadata": {
        "id": "jI84xZSyQerT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_checkpoint=10\n",
        "batch_size=100\n",
        "img_dim=784\n",
        "\n",
        "d_lr=0.0002\n",
        "g_lr=0.0002\n",
        "num_epochs=100\n",
        "dropout_rate=0.3\n",
        "\n",
        "z_dim=100\n",
        "g_steps=1\n",
        "d_steps=1\n",
        "\n",
        "model_path='/content/gdrive/My Drive/Colab Notebooks/GAN/MNIST-Models'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "miSOIGVVMiAo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load The MNIST Dataset"
      ]
    },
    {
      "metadata": {
        "id": "fKts_cpsrsiW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "28a2f078-1373-40ec-c7f5-a3b46cb4cc14"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zKxQFF0-MgPl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !mkdir /content/data\n",
        "data_root='/content/data'\n",
        "data_transforms = transforms.Compose([transforms.ToTensor(),\n",
        "                                      transforms.Lambda(lambda x: (x-0.5)/0.5)])\n",
        "\n",
        "train_set = datasets.MNIST(root=data_root, train=True, \n",
        "                           transform=data_transforms, download=True)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_set,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FBj7BioXWD0x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generator"
      ]
    },
    {
      "metadata": {
        "id": "kdj0TcC4WMzn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "  \n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.fc1 = nn.Linear(z_dim, 256)\n",
        "        self.fc2 = nn.Linear(256, 512)\n",
        "        self.fc3 = nn.Linear(512, 1024)\n",
        "        self.fc4 = nn.Linear(1024, img_dim)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        x = self.tanh(x)\n",
        "        return x.view(-1, 1, 28, 28)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pJSeuXh-WIOP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Discriminator"
      ]
    },
    {
      "metadata": {
        "id": "O_5jHqjSU04I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.fc1 = nn.Linear(img_dim, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 512)\n",
        "        self.fc3 = nn.Linear(512, 256)\n",
        "        self.fc4 = nn.Linear(256, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = self.fc4(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B8ql7LzFbPsj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training\n"
      ]
    },
    {
      "metadata": {
        "id": "7ZkG76HhfzpS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def extract(v):\n",
        "    return v.data.storage().tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WOg8YhDEeakX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "1ad29bd8-5dbd-46d9-ef81-ccaf493eaafc"
      },
      "cell_type": "code",
      "source": [
        "G = Generator()\n",
        "D = Discriminator()\n",
        "if use_cuda:\n",
        "  G = G.cuda()\n",
        "  D = D.cuda()\n",
        "criterion = nn.BCELoss()\n",
        "d_optimizer = optim.Adam(D.parameters(), lr=d_lr)\n",
        "g_optimizer = optim.Adam(G.parameters(), lr=g_lr)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (x, _) in enumerate(train_loader):\n",
        "  \n",
        "    if use_cuda:\n",
        "      x = x.cuda()\n",
        "\n",
        "    # 1. Train D on real+fake\n",
        "    D.zero_grad()\n",
        "\n",
        "    #  1A: Train D on real\n",
        "    d_real_data = Variable(x)\n",
        "    d_real_decision = D(d_real_data)\n",
        "    d_real_labels = torch.ones(batch_size) # ones = true\n",
        "    if use_cuda:\n",
        "      d_real_labels = d_real_labels.cuda()\n",
        "    d_real_error = criterion(d_real_decision, Variable(d_real_labels))  \n",
        "    d_real_error.backward() # compute/store gradients, but don't change params\n",
        "\n",
        "    #  1B: Train D on fake\n",
        "    d_z = torch.randn(batch_size, z_dim)\n",
        "    if use_cuda:\n",
        "      d_z = d_z.cuda()\n",
        "    d_gen_input = Variable(d_z)\n",
        "    d_fake_data = G(d_gen_input).detach()  # detach to avoid training G on these labels\n",
        "    d_fake_decision = D(d_fake_data)\n",
        "    d_fake_labels = torch.zeros(batch_size) # zeros = fake\n",
        "    if use_cuda:\n",
        "      d_fake_labels = d_fake_labels.cuda()\n",
        "    d_fake_error = criterion(d_fake_decision, Variable(d_fake_labels)) \n",
        "    d_fake_error.backward()\n",
        "    d_optimizer.step()     # Only optimizes D's parameters; changes based on stored gradients from backward()\n",
        "\n",
        "    # 2. Train G on D's response (but DO NOT train D on these labels)\n",
        "    G.zero_grad()\n",
        "\n",
        "    g_z = torch.randn(batch_size, z_dim)\n",
        "    if use_cuda:\n",
        "      g_z = g_z.cuda()\n",
        "    gen_input = Variable(g_z)\n",
        "    g_fake_data = G(gen_input)\n",
        "    dg_fake_decision = D(g_fake_data)\n",
        "    dg_fake_labels = torch.ones(batch_size)\n",
        "    if use_cuda:\n",
        "      dg_fake_labels = dg_fake_labels.cuda()\n",
        "    g_error = criterion(dg_fake_decision, Variable(dg_fake_labels))  # we want to fool, so pretend it's all genuine\n",
        "\n",
        "    g_error.backward()\n",
        "    g_optimizer.step()  # Only optimizes G's parameters\n",
        "\n",
        "  if epoch % num_checkpoint == 0:\n",
        "      print(\"%s: D: %s/%s G: %s\" % (epoch,\n",
        "                                    extract(d_real_error)[0],\n",
        "                                    extract(d_fake_error)[0],\n",
        "                                    extract(g_error)[0]))\n",
        "      torch.save(G, '%s/G-%s' % (model_path, epoch))\n",
        "      torch.save(D, '%s/D-%s' % (model_path, epoch))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1594: UserWarning: Using a target size (torch.Size([100])) that is different to the input size (torch.Size([100, 1])) is deprecated. Please ensure they have the same size.\n",
            "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0: D: 0.11455582827329636/0.10236942023038864 G: 7.5484089851379395\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Generator. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Discriminator. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10: D: 0.23482172191143036/0.030025305226445198 G: 5.575169563293457\n",
            "20: D: 0.21445044875144958/0.06041145697236061 G: 4.849595069885254\n",
            "30: D: 0.46275046467781067/0.27042749524116516 G: 3.479390859603882\n",
            "40: D: 0.16693933308124542/0.3283050060272217 G: 1.8957487344741821\n",
            "50: D: 0.3603785037994385/0.4635913372039795 G: 1.8412270545959473\n",
            "60: D: 0.5539034008979797/0.38797813653945923 G: 1.5795801877975464\n",
            "70: D: 0.3052400052547455/0.4595661163330078 G: 1.5909746885299683\n",
            "80: D: 0.4840969145298004/0.3414584994316101 G: 1.3388384580612183\n",
            "90: D: 0.5193278193473816/0.5698971748352051 G: 1.2950172424316406\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G2548uOgoegF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "d_z = torch.randn(batch_size, z_dim)\n",
        "if use_cuda:\n",
        "  d_z = d_z.cuda()\n",
        "results = G(Variable(d_z)).detach()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ebxNi1BjoyE6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "e236ac44-9f82-4546-ccc0-d7a5aa4e3eb3"
      },
      "cell_type": "code",
      "source": [
        "res = results.cpu().numpy()\n",
        "plt.imshow(1 - (res[1][0] / 2 + 0.5))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ffae016eda0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7ffae00df630>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}