{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN MNIST.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayush29feb/nn-experiments/blob/master/gan/GAN_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "jnC_3AJQMkII",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Generative Adversarial Networks: MNIST\n",
        "\n",
        "A simple GAN for generating handwritten digits drawings similar to MNIST Dataset"
      ]
    },
    {
      "metadata": {
        "id": "g0JtIWeRH3hz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7SqXbsEFLnUW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2dc47e35-d828-461d-ed21-eb0e484a9827"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.mlab as mlab\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torch.autograd import Variable\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "if use_cuda:\n",
        "  print('Using GPU: %s'% torch.cuda.get_device_name(0))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using GPU: Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ynaf-cO9QbPm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Parameters"
      ]
    },
    {
      "metadata": {
        "id": "jI84xZSyQerT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size=10\n",
        "img_dim=784\n",
        "\n",
        "d_lr=0.0002\n",
        "g_lr=0.0002\n",
        "num_epochs=100\n",
        "dropout_rate=0.3\n",
        "\n",
        "z_dim=100\n",
        "g_steps=1\n",
        "d_steps=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "miSOIGVVMiAo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load The MNIST Dataset"
      ]
    },
    {
      "metadata": {
        "id": "zKxQFF0-MgPl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !mkdir /content/data\n",
        "data_root='/content/data'\n",
        "data_transforms = transforms.Compose([transforms.ToTensor(),\n",
        "                                      transforms.Lambda(lambda x: (x-0.5)/0.5)])\n",
        "\n",
        "train_set = datasets.MNIST(root=data_root, train=True, \n",
        "                           transform=data_transforms, download=True)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_set,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FBj7BioXWD0x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generator"
      ]
    },
    {
      "metadata": {
        "id": "kdj0TcC4WMzn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "  \n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.fc1 = nn.Linear(z_dim, 256)\n",
        "        self.fc2 = nn.Linear(256, 512)\n",
        "        self.fc3 = nn.Linear(512, 1024)\n",
        "        self.fc4 = nn.Linear(1024, img_dim)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        x = self.tanh(x)\n",
        "        return x.view(-1, 1, 28, 28)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pJSeuXh-WIOP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Discriminator"
      ]
    },
    {
      "metadata": {
        "id": "O_5jHqjSU04I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.fc1 = nn.Linear(img_dim, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 512)\n",
        "        self.fc3 = nn.Linear(512, 256)\n",
        "        self.fc4 = nn.Linear(256, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = self.fc4(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B8ql7LzFbPsj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training\n"
      ]
    },
    {
      "metadata": {
        "id": "7ZkG76HhfzpS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def extract(v):\n",
        "    return v.data.storage().tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WOg8YhDEeakX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716
        },
        "outputId": "25364384-9f74-449c-803d-2ae3291c6f6f"
      },
      "cell_type": "code",
      "source": [
        "G = Generator()\n",
        "D = Discriminator()\n",
        "if use_cuda:\n",
        "  G = G.cuda()\n",
        "  D = D.cuda()\n",
        "criterion = nn.BCELoss()\n",
        "d_optimizer = optim.Adam(D.parameters(), lr=d_lr)\n",
        "g_optimizer = optim.Adam(G.parameters(), lr=g_lr)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (x, _) in enumerate(train_loader):\n",
        "  \n",
        "    if use_cuda:\n",
        "      x = x.cuda()\n",
        "\n",
        "    # 1. Train D on real+fake\n",
        "    D.zero_grad()\n",
        "\n",
        "    #  1A: Train D on real\n",
        "    d_real_data = Variable(x)\n",
        "    d_real_decision = D(d_real_data)\n",
        "    d_real_labels = torch.ones(batch_size) # ones = true\n",
        "    if use_cuda:\n",
        "      d_real_labels = d_real_labels.cuda()\n",
        "    d_real_error = criterion(d_real_decision, Variable(d_real_labels))  \n",
        "    d_real_error.backward() # compute/store gradients, but don't change params\n",
        "\n",
        "    #  1B: Train D on fake\n",
        "    d_z = torch.randn(batch_size, z_dim)\n",
        "    if use_cuda:\n",
        "      d_z = d_z.cuda()\n",
        "    d_gen_input = Variable(d_z)\n",
        "    d_fake_data = G(d_gen_input).detach()  # detach to avoid training G on these labels\n",
        "    d_fake_decision = D(d_fake_data)\n",
        "    d_fake_labels = torch.zeros(batch_size) # zeros = fake\n",
        "    if use_cuda:\n",
        "      d_fake_labels = d_fake_labels.cuda()\n",
        "    d_fake_error = criterion(d_fake_decision, Variable(d_fake_labels)) \n",
        "    d_fake_error.backward()\n",
        "    d_optimizer.step()     # Only optimizes D's parameters; changes based on stored gradients from backward()\n",
        "\n",
        "    # 2. Train G on D's response (but DO NOT train D on these labels)\n",
        "    G.zero_grad()\n",
        "\n",
        "    g_z = torch.randn(batch_size, z_dim)\n",
        "    if use_cuda:\n",
        "      g_z = g_z.cuda()\n",
        "    gen_input = Variable(g_z)\n",
        "    g_fake_data = G(gen_input)\n",
        "    dg_fake_decision = D(g_fake_data)\n",
        "    dg_fake_labels = torch.ones(batch_size)\n",
        "    if use_cuda:\n",
        "      dg_fake_labels = dg_fake_labels.cuda()\n",
        "    g_error = criterion(dg_fake_decision, Variable(dg_fake_labels))  # we want to fool, so pretend it's all genuine\n",
        "\n",
        "    g_error.backward()\n",
        "    g_optimizer.step()  # Only optimizes G's parameters\n",
        "\n",
        "  if epoch % 1 == 0:\n",
        "      print(\"%s: D: %s/%s G: %s\" % (epoch,\n",
        "                                    extract(d_real_error)[0],\n",
        "                                    extract(d_fake_error)[0],\n",
        "                                    extract(g_error)[0]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1594: UserWarning: Using a target size (torch.Size([10])) that is different to the input size (torch.Size([10, 1])) is deprecated. Please ensure they have the same size.\n",
            "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0: D: 0.008815480396151543/0.019994014874100685 G: 5.408061981201172\n",
            "1: D: 0.0064512281678617/0.04888596385717392 G: 2.3822500705718994\n",
            "2: D: 0.0018764892593026161/0.514936625957489 G: 2.416656494140625\n",
            "3: D: 0.5222370028495789/0.3136095404624939 G: 2.527367115020752\n",
            "4: D: 0.6542896032333374/0.4390343725681305 G: 1.9788920879364014\n",
            "5: D: 0.14024768769741058/0.3854864239692688 G: 1.1669175624847412\n",
            "6: D: 0.8473265767097473/0.32413625717163086 G: 1.9464260339736938\n",
            "7: D: 0.537171483039856/0.28617867827415466 G: 1.3709501028060913\n",
            "8: D: 0.66823810338974/0.49794521927833557 G: 1.4135640859603882\n",
            "9: D: 0.669575572013855/0.4740068316459656 G: 1.4080054759979248\n",
            "10: D: 0.4708629250526428/0.3165932893753052 G: 1.2402751445770264\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-c8820d3c3c63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mg_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdg_fake_decision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdg_fake_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# we want to fool, so pretend it's all genuine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mg_error\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mg_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Only optimizes G's parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "G2548uOgoegF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "d_z = torch.randn(batch_size, z_dim)\n",
        "if use_cuda:\n",
        "  d_z = d_z.cuda()\n",
        "results = G(Variable(d_z)).detach()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ebxNi1BjoyE6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "80e7495c-2371-431e-da7b-3a01338796e9"
      },
      "cell_type": "code",
      "source": [
        "res = results.cpu().numpy()\n",
        "plt.imshow(1 - (res[7][0] / 2 + 0.5))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff0abefe9e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8prsEwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7ff0abf0d4a8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}